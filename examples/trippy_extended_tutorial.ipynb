{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRIPPY_RESTAURANT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4R066YWhTgU6",
        "n597CLhqjqcd",
        "XeJMI9qaTgVt"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ5jRYn-rsBU"
      },
      "source": [
        "### You can also run the notebook in [COLAB](https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/trippy_extended_tutorial.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPbAiv8KTgU4"
      },
      "source": [
        "# TripPy Goal oriented bot in DeepPavlov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL-qtlM3l51N"
      },
      "source": [
        "This tutorial describes how to build an **advanced** Goal-Oriented Bot (Gobot) in DeepPavlov using the [TripPy architecture](https://arxiv.org/pdf/2005.02877.pdf).\n",
        "You can also train a simple bot following the trippy_simple tutorial.\n",
        "\n",
        "\n",
        "This tutorial follows the same structure & uses the same data as the gobot_extended tutorial. We will only go over TripPy specific points here - so consult the gobot_extended notebook for general insights. Note that the only difference is the config used and fewer steps being needed for TripPy.\n",
        "\n",
        "0. [Data preparation](#0.-Data-Preparation)\n",
        "1. [Build Database of items](#1.-Build-Database-of-items)\n",
        "2. [Build and Train a Bot](#3.-Build-and-Train-a-Bot)\n",
        "3. [Interact with bot](#4.-Interact-with-Bot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vtu-7ns2TgUz",
        "outputId": "7ebb4ff8-5360-4c34-952e-a98f7a7210b6"
      },
      "source": [
        "!git clone -b rulebased_gobot_trippy https://github.com/Muennighoff/DeepPavlov\n",
        "%cd DeepPavlov\n",
        "!pip install -r requirements.txt\n",
        "!pip install transformers==2.9.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepPavlov'...\n",
            "remote: Enumerating objects: 58503, done.\u001b[K\n",
            "remote: Counting objects: 100% (1446/1446), done.\u001b[K\n",
            "remote: Compressing objects: 100% (519/519), done.\u001b[K\n",
            "remote: Total 58503 (delta 1089), reused 1224 (delta 914), pack-reused 57057\u001b[K\n",
            "Receiving objects: 100% (58503/58503), 37.54 MiB | 22.41 MiB/s, done.\n",
            "Resolving deltas: 100% (44934/44934), done.\n",
            "/content/DeepPavlov\n",
            "Collecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 11.6MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 48.0MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 43.9MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 48.2MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 25.3MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 30.3MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 20.2MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 35.3MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.4.1)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (4.41.1)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (7.1.2)\n",
            "Collecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 42.6MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 41.6MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 52.7MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->-r requirements.txt (line 13)) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 18.9MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.1MB/s \n",
            "\u001b[?25hCollecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->-r requirements.txt (line 17)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->-r requirements.txt (line 17)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->-r requirements.txt (line 17)) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->-r requirements.txt (line 20)) (1.0.1)\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.7MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2e/485131e3aa113929b425f83854fafc190aa7df716cbeb258c875752f0c6e/httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 56.7MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 58.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->-r requirements.txt (line 15)) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->-r requirements.txt (line 15)) (2.20)\n",
            "Building wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449923 sha256=46610e717d6cb131a88074f3e94e333b82def5bbcfdb22df0c284f77e9a9e997\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5606 sha256=aa7cfc537b65e68f420abf9b73fecccdb114445be38e40f561ea4ba58459605a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=5c6da21f656d11625bb3e5b2dbc6a7c40f78d7444814220199e51adb239f1898\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=76263248541344addd51d9255597c5ea7e74170453b75dca88c0e51f29a6e15e\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883990 sha256=7c9c6f14c9b9b2139642a4baceb86e08dfb7951eb5dbae8706f091e919f69c39\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57254 sha256=768534bf0237d07c2b003f4470984b896935bce261b1ee4929217a82270b6843\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
            "\u001b[31mERROR: xarray 0.18.2 has requirement pandas>=1.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pamqp, idna, multidict, yarl, aiormq, aio-pika, Cython, pydantic, starlette, fastapi, numpy, h5py, nltk, overrides, pytz, pandas, prometheus-client, pymorphy2-dicts, dawg-python, pymorphy2, pymorphy2-dicts-ru, cryptography, pyopenssl, requests, pytelegrambotapi, ruamel.yaml, rusenttokenize, scikit-learn, h11, httptools, uvloop, websockets, uvicorn, sacremoses\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: Cython 0.29.23\n",
            "    Uninstalling Cython-0.29.23:\n",
            "      Successfully uninstalled Cython-0.29.23\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: prometheus-client 0.11.0\n",
            "    Uninstalling prometheus-client-0.11.0:\n",
            "      Successfully uninstalled prometheus-client-0.11.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 fastapi-0.47.1 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (0.0.35)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (2.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (1.18.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/59/bb06dd5ca53547d523422d32735585493e0103c992a52a97ba3aa3be33bf/tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.1) (1.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.1) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.1) (2021.5.30)\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers\n",
            "Successfully installed sentencepiece-0.1.96 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R066YWhTgU6"
      },
      "source": [
        "## 0. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9lF3QFJTgU8",
        "outputId": "8405c69b-60e2-46db-c6b6-edb3da867270"
      },
      "source": [
        "from deeppavlov.dataset_readers.dstc2_reader import SimpleDSTC2DatasetReader\n",
        "\n",
        "data = SimpleDSTC2DatasetReader().read('my_data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 13:54:25.72 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 283: [PosixPath('my_data/simple-dstc2-val.json'), PosixPath('my_data/simple-dstc2-tst.json')]]\n",
            "2021-07-12 13:54:25.73 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 284: [downloading data from http://files.deeppavlov.ai/datasets/simple_dstc2.tar.gz to my_data]\n",
            "2021-07-12 13:54:25.74 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/datasets/simple_dstc2.tar.gz to my_data/simple_dstc2.tar.gz\n",
            "100%|██████████| 497k/497k [00:00<00:00, 691kB/s]\n",
            "2021-07-12 13:54:27.359 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting my_data/simple_dstc2.tar.gz archive into my_data\n",
            "2021-07-12 13:54:27.402 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 304: [loading dialogs from my_data/simple-dstc2-trn.json]\n",
            "2021-07-12 13:54:27.528 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 304: [loading dialogs from my_data/simple-dstc2-val.json]\n",
            "2021-07-12 13:54:27.580 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 304: [loading dialogs from my_data/simple-dstc2-tst.json]\n",
            "2021-07-12 13:54:27.708 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 296: There are 9115 samples in train split.\n",
            "2021-07-12 13:54:27.709 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 297: There are 6231 samples in valid split.\n",
            "2021-07-12 13:54:27.715 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 298: There are 6345 samples in test split.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu56jAGJTgVD",
        "outputId": "9c9de6f6-bf81-4266-c140-7c8ae0852591"
      },
      "source": [
        "!ls my_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simple-dstc2-templates.txt  simple-dstc2-tst.json\n",
            "simple-dstc2-trn.json\t    simple-dstc2-val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO4CWg0XYNSw"
      },
      "source": [
        "To iterate over batches of preprocessed DSTC-2 we need to import `DatasetIterator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piBBcw9ZTgVK",
        "scrolled": true
      },
      "source": [
        "from deeppavlov.dataset_iterators.dialog_iterator import DialogDatasetIterator\n",
        "\n",
        "iterator = DialogDatasetIterator(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVU5JGnTTgVM"
      },
      "source": [
        "You can now iterate over batches of preprocessed DSTC-2 dialogs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSwEH3CTgVN",
        "outputId": "28fff330-b559-471e-d8eb-bb8abbc8ce3e"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "for dialog in iterator.gen_batches(batch_size=1, data_type='train'):\n",
        "    turns_x, turns_y = dialog\n",
        "    \n",
        "    print(\"User utterances:\\n----------------\\n\")\n",
        "    pprint(turns_x[0], indent=4)\n",
        "    print(\"\\nSystem responses:\\n-----------------\\n\")\n",
        "    pprint(turns_y[0], indent=4)\n",
        "    \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User utterances:\n",
            "----------------\n",
            "\n",
            "[   {'prev_resp_act': None, 'text': ''},\n",
            "    {   'prev_resp_act': 'welcomemsg',\n",
            "        'slots': [['area', 'west'], ['pricerange', 'cheap']],\n",
            "        'text': 'can i have a cheap restaurant in the west part of town'},\n",
            "    {   'db_result': {   'addr': '17 magdalene street city centre',\n",
            "                         'area': 'west',\n",
            "                         'food': 'vietnamese',\n",
            "                         'name': 'thanh binh',\n",
            "                         'phone': '01223 362456',\n",
            "                         'postcode': 'c.b 3, 0 a.f',\n",
            "                         'pricerange': 'cheap'},\n",
            "        'prev_resp_act': 'api_call',\n",
            "        'slots': [['area', 'west'], ['pricerange', 'cheap']],\n",
            "        'text': 'can i have a cheap restaurant in the west part of town'},\n",
            "    {   'prev_resp_act': 'inform_area+inform_pricerange+offer_name',\n",
            "        'slots': [['slot', 'phone']],\n",
            "        'text': 'can i have the phone number'},\n",
            "    {'prev_resp_act': 'inform_phone+offer_name', 'text': 'thank you good bye'}]\n",
            "\n",
            "System responses:\n",
            "-----------------\n",
            "\n",
            "[   {   'act': 'welcomemsg',\n",
            "        'text': 'Hello, welcome to the Cambridge restaurant system. You can '\n",
            "                'ask for restaurants by area, price range or food type. How '\n",
            "                'may I help you?'},\n",
            "    {   'act': 'api_call',\n",
            "        'slots': [['area', 'west'], ['pricerange', 'cheap']],\n",
            "        'text': 'api_call area=\"west\" food=\"dontcare\" pricerange=\"cheap\"'},\n",
            "    {   'act': 'inform_area+inform_pricerange+offer_name',\n",
            "        'slots': [   ['area', 'west'],\n",
            "                     ['name', 'thanh binh'],\n",
            "                     ['pricerange', 'cheap']],\n",
            "        'text': 'Thanh binh is a nice place in the west of town and the prices '\n",
            "                'are cheap.'},\n",
            "    {   'act': 'inform_phone+offer_name',\n",
            "        'slots': [['phone', '01223 362456'], ['name', 'thanh binh']],\n",
            "        'text': 'The phone number of thanh binh is 01223 362456.'},\n",
            "    {'act': 'bye', 'text': 'You are welcome!'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKTZWtm8ZtPi"
      },
      "source": [
        "In real-life annotation of data is expensive. To make our tutorial closer to production use-cases we take  only 50 dialogues for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlappYTbTgVT"
      },
      "source": [
        "!cp my_data/simple-dstc2-trn.json my_data/simple-dstc2-trn.full.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTU9yM-CTgVX",
        "outputId": "46c98790-a2f1-4347-aa5d-ffc3fd90fb28"
      },
      "source": [
        "import json\n",
        "\n",
        "NUM_TRAIN = 967\n",
        "\n",
        "with open('my_data/simple-dstc2-trn.full.json', 'rt') as fin:\n",
        "    data = json.load(fin)\n",
        "with open('my_data/simple-dstc2-trn.json', 'wt') as fout:\n",
        "    json.dump(data[:NUM_TRAIN], fout, indent=2)\n",
        "print(f\"Train set is reduced to {NUM_TRAIN} dialogues (out of {len(data)}).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set is reduced to 50 dialogues (out of 967).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5mjRphbTgVb"
      },
      "source": [
        "## 1. Build Database of items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n597CLhqjqcd"
      },
      "source": [
        "### Building database of restaurants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjKbIAyaTgVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfccce7-a9b8-4a70-9f80-9b3e9e3b98fd"
      },
      "source": [
        "from deeppavlov.core.data.sqlite_database import Sqlite3Database\n",
        "\n",
        "database = Sqlite3Database(primary_keys=[\"name\"],\n",
        "                           save_path=\"my_bot/db.sqlite\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 13:54:28.484 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for Sqlite3Database in 'infer' mode. Using save path instead\n",
            "2021-07-12 13:54:28.485 INFO in 'deeppavlov.core.data.sqlite_database'['sqlite_database'] at line 70: Initializing empty database on /content/DeepPavlov/my_bot/db.sqlite.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlKg5UtqTgVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d78e25e-9c40-42e8-8c87-9b47e1cd987c"
      },
      "source": [
        "db_results = []\n",
        "\n",
        "for dialog in iterator.gen_batches(batch_size=1, data_type='all'):\n",
        "    turns_x, turns_y = dialog\n",
        "    db_results.extend(x['db_result'] for x in turns_x[0] if x.get('db_result'))\n",
        "\n",
        "print(f\"Adding {len(db_results)} items.\")\n",
        "if db_results:\n",
        "    database.fit(db_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 13:54:28.524 INFO in 'deeppavlov.core.data.sqlite_database'['sqlite_database'] at line 130: Created table with keys {'pricerange': 'text', 'area': 'text', 'addr': 'text', 'phone': 'text', 'postcode': 'text', 'food': 'text', 'name': 'text'}.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Adding 3016 items.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeJMI9qaTgVt"
      },
      "source": [
        "### Interacting with database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JLUF2b_TgVu"
      },
      "source": [
        "We can now play with the database and make requests to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRCU_MJnTgVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612364d9-1f42-4947-8624-2f74cd2b6457"
      },
      "source": [
        "database([{'pricerange': 'cheap', 'area': 'south'}])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'addr': 'cambridge leisure park clifton way cherry hinton',\n",
              "   'area': 'south',\n",
              "   'food': 'chinese',\n",
              "   'name': 'the lucky star',\n",
              "   'phone': '01223 244277',\n",
              "   'postcode': 'c.b 1, 7 d.y',\n",
              "   'pricerange': 'cheap'},\n",
              "  {'addr': 'cambridge leisure park clifton way',\n",
              "   'area': 'south',\n",
              "   'food': 'portuguese',\n",
              "   'name': 'nandos',\n",
              "   'phone': '01223 327908',\n",
              "   'postcode': 'c.b 1, 7 d.y',\n",
              "   'pricerange': 'cheap'}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_InRKO6TgWt"
      },
      "source": [
        "## 3. Build and Train a Bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skZd9O3bKHMo"
      },
      "source": [
        "The below image comes from the [TripPy paper](https://arxiv.org/pdf/2005.02877.pdf) and sketches out the models architecture.\n",
        "\n",
        "&nbsp;\n",
        "![trippy_architecture_original.png](img/trippy_architecture_original.jpg)\n",
        "&nbsp;\n",
        "\n",
        "The entire dialogue history, the last system & user utterances are tokenized and fed into a [BERT Model](https://arxiv.org/pdf/1810.04805.pdf). The model makes use of attention to calculate the importance of tokens in the input. In TripPy the BERT model is trained to do binary clasification for each input token in regards to whether it is a slot value of one of the predefined slot names.\n",
        "\n",
        "For example, for the slot name \"pricerange\" the model will look at each token and classify whether it corresponds to that slot. For the input: *I want cheap food*, the output for pricerange should be [0,0,1,0], hence identifying that cheap corresponds to the pricerange. This span prediction is then used to copy the value out of the input.\n",
        "\n",
        "Apart from \"span\" (also called \"copy_value\"), other \"class types\" (Predictions made for each slot name) are: \n",
        "- \"dontcare\" The model thinks the user does not care about this slot name's value\n",
        "- \"none\": The user has not yet indicated his preference for this slot name\n",
        "- \"refer\": The user has indicated his preference via another slot name\n",
        "- \"inform\": The model has previously informed the user about the slot name\n",
        "- \"true / false\": Used when there are slotnames with boolean values\n",
        "\n",
        "Below is a sketch for how the full TripPy model has been implemented in DeepPavlov:\n",
        "\n",
        "&nbsp;\n",
        "![trippy_architecture.png](img/trippy_architecture.png)\n",
        "&nbsp;\n",
        "\n",
        "The above image also includes the input & input processing steps, while the previous sketch starts with the BERT Model (BERTForDST). \n",
        "Novel things in the DeepPavlov TripPy implementation are:\n",
        "- The preprocessing is robust to datasets which do not contain position labels (During training TripPy requires position labels to train up its copy value capabilities) - This has been done by calculating Levenshtein distances\n",
        "- An action prediction head has been added, which predicts what action the system should take from a predefined list of actions\n",
        "- A database connection has been added, which allows the model to retrieve information about slot values from an sqlite Database\n",
        "- A Natural Language Generation component has been added, which takes in the predicted action and database results and puts together the final response tothe user\n",
        "\n",
        "\n",
        "We will now proceed with configuring the model & training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db9_ozwnTgW5"
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "# Use TripPy Config\n",
        "gobot_config = read_json(configs.go_bot.trippy_dstc2_minimal)\n",
        "\n",
        "gobot_config['chainer']['pipe'][-1]['nlg_manager']['template_type'] = 'DefaultTemplate'\n",
        "gobot_config['chainer']['pipe'][-1]['nlg_manager']['template_path'] = 'my_data/simple-dstc2-templates.txt'\n",
        "\n",
        "gobot_config['metadata']['variables']['DATA_PATH'] = 'my_data'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = 'my_bot'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNGj-ARxTgW-"
      },
      "source": [
        "\n",
        "\n",
        "Configure bot to use our database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VanrlHZZTgXB"
      },
      "source": [
        "gobot_config['chainer']['pipe'][-1]['database'] = {\n",
        "    'class_name': 'sqlite_database',\n",
        "    'primary_keys': [\"name\"],\n",
        "    'save_path': 'my_bot/db.sqlite'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6H_t1iTgW7"
      },
      "source": [
        "Configure bot to use templates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "209m3f6yTgW8"
      },
      "source": [
        "gobot_config['chainer']['pipe'][-1]['nlg_manager']['template_type'] = 'DefaultTemplate'\n",
        "gobot_config['chainer']['pipe'][-1]['nlg_manager']['template_path'] = 'my_data/simple-dstc2-templates.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMXih1roTgXi"
      },
      "source": [
        "Specify train/valid/test data path and path to save the final bot model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTUdrrQVTgXi"
      },
      "source": [
        "gobot_config['metadata']['variables']['DATA_PATH'] = 'my_data'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = 'my_bot'\n",
        "# Configure the possible slot names - The \"this\" slotname is meaningless, but it is somehow part of the training set\n",
        "gobot_config['chainer']['pipe'][-1]['slot_names'] = ['pricerange', 'this', 'area', 'food']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ekUezSjWGEz"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "gobot_config['train']['batch_size'] = 4 # set batch size - Ideally use 8 & set lr to 1e-4 if your GPU allows\n",
        "gobot_config['train']['max_batches'] = 600 # maximum number of training batches\n",
        "gobot_config['train']['val_every_n_batches'] = 40 # evaluate on full 'valid' split every x epochs\n",
        "gobot_config['train']['log_every_n_batches'] = 40 # evaluate on full 'train' split every x batches\n",
        "gobot_config['train']['validation_patience'] = 10 # evaluate on full 'valid' split every x epochs\n",
        "gobot_config['train']['log_on_k_batches'] = 10 # How many batches to use for logging\n",
        "\n",
        "gobot_config['chainer']['pipe'][-1]['debug'] = False\n",
        "gobot_config['chainer']['pipe'][-1][\"optimizer_parameters\"] = {\"lr\": 1e-5, \"eps\": 1e-6}\n",
        "\n",
        "train_model(gobot_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCHybLSa_Gzx"
      },
      "source": [
        "Optionally, you can download the pre-trained model from kaggle. You will need a kaggle account and to upload your kaggle.json file. Then you may have to run the below cell two times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-U6mvu-js-",
        "outputId": "8da1fcc0-4669-4ae7-a9f3-053dcdfa2aff"
      },
      "source": [
        "### Optional - Download Pretrained TripPy from kaggle ###\n",
        "\n",
        "# Make your json accessible to kaggle\n",
        "#!cp /content/kaggle.json /root/.kaggle/\n",
        "\n",
        "# Download the dataset\n",
        "#!kaggle datasets download -d muennighoff/trippy-restaurant\n",
        "#!unzip trippy-restaurant.zip\n",
        "\n",
        "# Move into correct directory\n",
        "#!mv db.sqlite /content/DeepPavlov/my_bot/\n",
        "#!mv model.pth.tar /content/DeepPavlov/my_bot/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading trippy-restaurant.zip to /content/DeepPavlov\n",
            " 99% 985M/993M [00:09<00:00, 120MB/s]\n",
            "100% 993M/993M [00:09<00:00, 110MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldfDa9dUTgX1"
      },
      "source": [
        "### Evaluation of training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-z7wZjOTgX6"
      },
      "source": [
        "Calculating **accuracy** of trained bot: whether predicted system responses match true responses (full string match)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INAcWeKfHR63"
      },
      "source": [
        "from deeppavlov import evaluate_model\n",
        "\n",
        "evaluate_model(gobot_config);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wZOqmYBTgYB"
      },
      "source": [
        "With settings of `max_batches=800`, valid accuracy `= 0.44` and test accuracy is `~ 0.45`.\n",
        "\n",
        "\n",
        "If you have the compute, try training the model with a higher batch size, such as 8, or 16. The code automatically detects multiple GPUs and will run Data Parallelism. You will, however, need to upgrade the transformers huggingface version to 4.X and fix two transfomrer import statements in the TripPy code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElGD1tnJTgYC"
      },
      "source": [
        "## 4. Interact with Bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9sJXOPPTgYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5521fe8a-c538-4e7c-ee16-bd8ca7962133"
      },
      "source": [
        "from deeppavlov import build_model\n",
        "\n",
        "bot = build_model(gobot_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 14:09:13.926 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for Sqlite3Database in 'infer' mode. Using save path instead\n",
            "2021-07-12 14:09:13.932 INFO in 'deeppavlov.core.data.sqlite_database'['sqlite_database'] at line 66: Loading database from /content/DeepPavlov/my_bot/db.sqlite.\n",
            "2021-07-12 14:09:17.459 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 152: Load path /content/DeepPavlov/my_bot/model is given.\n",
            "2021-07-12 14:09:17.461 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 159: Load path /content/DeepPavlov/my_bot/model.pth.tar exists.\n",
            "2021-07-12 14:09:17.463 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 160: Initializing `TripPy` from saved.\n",
            "2021-07-12 14:09:17.465 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 163: Loading weights from /content/DeepPavlov/my_bot/model.pth.tar.\n",
            "2021-07-12 14:09:18.263 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 98: Model was successfully initialized! Model summary:\n",
            " BertForDST(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (dropout_heads): Dropout(p=0.0, inplace=False)\n",
            "  (inform_projection): Linear(in_features=4, out_features=4, bias=True)\n",
            "  (ds_projection): Linear(in_features=4, out_features=4, bias=True)\n",
            "  (class_pricerange): Linear(in_features=776, out_features=4, bias=True)\n",
            "  (token_pricerange): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (refer_pricerange): Linear(in_features=776, out_features=5, bias=True)\n",
            "  (class_this): Linear(in_features=776, out_features=4, bias=True)\n",
            "  (token_this): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (refer_this): Linear(in_features=776, out_features=5, bias=True)\n",
            "  (class_area): Linear(in_features=776, out_features=4, bias=True)\n",
            "  (token_area): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (refer_area): Linear(in_features=776, out_features=5, bias=True)\n",
            "  (class_food): Linear(in_features=776, out_features=4, bias=True)\n",
            "  (token_food): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (refer_food): Linear(in_features=776, out_features=5, bias=True)\n",
            "  (action_prediction): Linear(in_features=776, out_features=46, bias=True)\n",
            "  (action_softmax): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVLHl5jlpQMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9253ffc9-1b96-4175-d360-e8acc502dca2"
      },
      "source": [
        "bot.reset()\n",
        "bot(['hi, i want to eat, can you suggest a place to go?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What kind of food would you like?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb6AutTSpRUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d1529e-c231-4a23-bfd7-a47217f8bb05"
      },
      "source": [
        "bot(['Perhaps something cheap'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What part of town do you have in mind?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTBEMEIUpizH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa69cb75-598e-4a04-af84-d196df2b1290"
      },
      "source": [
        "bot(['In the north of town'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-16 14:09:36.730 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 390: Made api_call with dict_keys(['pricerange', 'this', 'area', 'food']), got 11 results.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['api_call area=\"north\" food=\"dontcare\" pricerange=\"dontcare\"',\n",
              "  'Meghna is a nice place in the north of town and the prices are moderate.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW52c1G9ptRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7727c106-235c-4e93-9424-27927220e8c8"
      },
      "source": [
        "bot(['Whats their phone number?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The phone number of meghna is 01223 727410.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY3DASP-pxdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2b1c61-9710-4bb6-a00c-d988fd0cbcd0"
      },
      "source": [
        "bot(['and the address?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Sure, meghna is on 205 victoria road chesterton.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7THguiXmp0PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001fc2e9-e071-4877-fc95-08360c052748"
      },
      "source": [
        "bot(['whats their pricerange again?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The price range at meghna is moderate.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naZd8YNmp5-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2954c809-2bae-4ad5-c24f-ec1aa22c4fc6"
      },
      "source": [
        "bot(['Alright sounds good, thank you!'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['You are welcome!']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JLME42dAk_n"
      },
      "source": [
        "#### Original\n",
        "\n",
        "These are examples used in the original DeepPavlov Go Bot Extended Tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyLNMrdzZyxJ",
        "outputId": "3bb4387c-6af8-4db2-ec21-633364c58f8a"
      },
      "source": [
        "bot.reset()\n",
        "bot(['hi, i want to eat, can you suggest a place to go?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What kind of food would you like?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxl8B_YEDR0D",
        "outputId": "2cceffc0-6a42-4be2-f348-706e52f11700"
      },
      "source": [
        "bot(['i want cheap food'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What part of town do you have in mind?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkZWwPxzDRv7",
        "outputId": "af0d0249-4b4f-4ff0-8bfa-e220505f210d"
      },
      "source": [
        "bot(['chinese food'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 14:10:38.514 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 390: Made api_call with dict_keys(['pricerange', 'this', 'area', 'food']), got 16 results.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['api_call area=\"dontcare\" food=\"chinese\" pricerange=\"dontcare\"',\n",
              "  'The good luck chinese food takeaway serves chinese food in the expensive price range.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRd7r-sGDRtb",
        "outputId": "5598de1c-bc4d-4648-ee02-143ddfbf25b4"
      },
      "source": [
        "bot(['thanks, give me their address'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Sure, the good luck chinese food takeaway is on 82 cherry hinton road cherry hinton.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9sWkiADtWR",
        "outputId": "4df322b2-3e2a-4b07-fe3b-be0f24a3c3df"
      },
      "source": [
        "bot(['i want their phone number too'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The phone number of the good luck chinese food takeaway is 01223 244149.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2K32hrDtT6",
        "outputId": "18c8bb83-79a7-461b-8253-b6de52313960"
      },
      "source": [
        "bot(['bye'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The good luck chinese food takeaway serves chinese food in the expensive price range.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKjYMOoDtQi",
        "outputId": "06c70c6c-69dc-4837-cefe-a8772c52aa00"
      },
      "source": [
        "bot.reset()\n",
        "bot(['Have you ever been in Cambridge?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 14:13:57.850 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 390: Made api_call with dict_keys(['pricerange', 'this', 'area', 'food']), got 109 results.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['api_call area=\"dontcare\" food=\"dontcare\" pricerange=\"dontcare\"',\n",
              "  'Frankie and bennys is a great restaurant.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwgP5xiRDtOv",
        "outputId": "40f74cca-feda-476b-a8bb-db9432b0f141"
      },
      "source": [
        "bot.reset()\n",
        "bot(['Can you suggest me a portuguese restaurant in Cambridge?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 14:16:43.903 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 390: Made api_call with dict_keys(['pricerange', 'this', 'area', 'food']), got 2 results.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['api_call area=\"dontcare\" food=\"portuguese\" pricerange=\"dontcare\"',\n",
              "  'Nandos serves portuguese food.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2gxspn9DtMS",
        "outputId": "22ebe4c1-059a-4755-c6e3-66f5b9f769aa"
      },
      "source": [
        "bot(['Does it have sangria?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Nandos serves portuguese food.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_wrfg3BC0jb",
        "outputId": "3c1b185d-cf3f-484a-b9ac-1a4aa9327c2b"
      },
      "source": [
        "bot.reset()\n",
        "bot(['Where can I get good pizza?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['You are welcome!']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qj3A6uiFUgb",
        "outputId": "a31a10b1-879d-4fc7-bbef-c53a7be0495b"
      },
      "source": [
        "bot(['Where can I get good pizza?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What part of town do you have in mind?']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouA7sJmoFYmb",
        "outputId": "048f2dad-f2f5-4d5b-a7e2-c44d61c26890"
      },
      "source": [
        "bot(['South of town'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-12 14:18:43.686 INFO in 'deeppavlov.models.go_bot.trippy'['trippy'] at line 390: Made api_call with dict_keys(['pricerange', 'this', 'area', 'food']), got 9 results.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['api_call area=\"south\" food=\"dontcare\" pricerange=\"dontcare\"',\n",
              "  'Frankie and bennys is a nice place in the south of town and the prices are expensive.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1y1Cz_yFoY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0378be3a-61b3-4cb7-f2d3-948f362aeed9"
      },
      "source": [
        "bot(['Whats their phone number?'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The phone number of frankie and bennys is 01223 412430.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N_9hOAoL_Yx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}